{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###A basic YOLO architecture:\n",
        "\n",
        "A simplified YOLO model with the following:\n",
        "1. Convolutional backbone\n",
        "2. Feature extraction\n",
        "3. Classification head"
      ],
      "metadata": {
        "id": "dzjcc9aNPFIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic Convolution block:\n",
        "Conv2D -> BatchNorm -> ReLU"
      ],
      "metadata": {
        "id": "tQjnJDYBQxrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Tuple, List, Dict, Optional\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Conv2d -> BatchNorm -> ReLU\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input channels\n",
        "        out_channels (int): Number of output channels\n",
        "        kernel_size (int): Size of the convolutional kernel\n",
        "        stride (int): Stride of the convolution\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int = 3,\n",
        "        stride: int = 1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "rc7bg896Q4cR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic YOLO architecture\n",
        "\n",
        "Model Structure:\n",
        "\n",
        "1.   Feature Extraction:\n",
        "        *   Stage 1: 416x416 -> 208x208 (32 channels)\n",
        "        *   Stage 2: 208x208 -> 104x104 (64 channels)\n",
        "        *   Stage 3: 104x104 -> 52x52 (128 channels)\n",
        "        *   Stage 4: 52x52 -> 26x26 (256 channels)\n",
        "\n",
        "2.   Classification Head:\n",
        "\n",
        "        *   Global Average Pooling\n",
        "        *   Fully Connected Layers\n"
      ],
      "metadata": {
        "id": "l72ogK7CRUjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicYOLO(nn.Module):\n",
        "    \"\"\"Basic YOLO architecture for classification.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of output classes\n",
        "        input_shape (Tuple[int, int, int]): Input shape (channels, height, width)\n",
        "        class_names (List[str], optional): Names of the classes\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        input_shape: Tuple[int, int, int],\n",
        "        class_names: Optional[List[str]] = None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Validate input shape\n",
        "        channels, height, width = input_shape\n",
        "        assert channels == 3, f\"Expected 3 input channels, got {channels}\"\n",
        "        assert height == width, f\"Expected square input, got height={height}, width={width}\"\n",
        "\n",
        "        # Initialize protected attributes directly\n",
        "        self._input_shape = input_shape\n",
        "        self._num_classes = num_classes\n",
        "        self._class_names = class_names if class_names else [f\"class_{i}\" for i in range(num_classes)]\n",
        "\n",
        "        # Backbone network - 4 stages of convolution blocks\n",
        "        self.features = nn.Sequential(\n",
        "            # Stage 1: 416x416 -> 208x208\n",
        "            ConvBlock(channels, 32, stride=2),\n",
        "            ConvBlock(32, 32),\n",
        "\n",
        "            # Stage 2: 208x208 -> 104x104\n",
        "            ConvBlock(32, 64, stride=2),\n",
        "            ConvBlock(64, 64),\n",
        "\n",
        "            # Stage 3: 104x104 -> 52x52\n",
        "            ConvBlock(64, 128, stride=2),\n",
        "            ConvBlock(128, 128),\n",
        "            ConvBlock(128, 128),\n",
        "\n",
        "            # Stage 4: 52x52 -> 26x26\n",
        "            ConvBlock(128, 256, stride=2),\n",
        "            ConvBlock(256, 256),\n",
        "            ConvBlock(256, 256)\n",
        "        )\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self, x: torch.Tensor, threshold: float = 0.5) -> List[Dict[str, float]]:\n",
        "        \"\"\"Predict class probabilities and labels for input images.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width)\n",
        "            threshold (float, optional): Confidence threshold for predictions. Defaults to 0.5.\n",
        "\n",
        "        Returns:\n",
        "            List[Dict[str, float]]: List of dictionaries containing class probabilities\n",
        "        \"\"\"\n",
        "        self.eval()  # Set to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            # Get model predictions\n",
        "            logits = self(x)\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "            # Convert to numpy for easier processing\n",
        "            probs_np = probs.cpu().numpy()\n",
        "\n",
        "            # Process each image's predictions\n",
        "            batch_predictions = []\n",
        "            for image_probs in probs_np:\n",
        "                # Get predictions above threshold\n",
        "                class_predictions = {}\n",
        "                for class_idx, prob in enumerate(image_probs):\n",
        "                    if prob >= threshold:\n",
        "                        class_predictions[self._class_names[class_idx]] = float(prob)\n",
        "\n",
        "                # If no class meets threshold, return highest probability class\n",
        "                if not class_predictions:\n",
        "                    max_idx = image_probs.argmax()\n",
        "                    class_predictions[self._class_names[max_idx]] = float(image_probs[max_idx])\n",
        "\n",
        "                batch_predictions.append(class_predictions)\n",
        "\n",
        "        return batch_predictions\n",
        "\n",
        "    def get_input_shape(self) -> Tuple[int, int, int]:\n",
        "        \"\"\"Get expected input shape.\"\"\"\n",
        "        return self._input_shape\n",
        "\n",
        "    def get_num_classes(self) -> int:\n",
        "        \"\"\"Get number of output classes.\"\"\"\n",
        "        return self._num_classes\n",
        "\n",
        "    def get_class_names(self) -> List[str]:\n",
        "        \"\"\"Get list of class names.\"\"\"\n",
        "        return self._class_names\n",
        "\n",
        "    def set_class_names(self, class_names: List[str]):\n",
        "        \"\"\"Set class names.\n",
        "\n",
        "        Args:\n",
        "            class_names (List[str]): List of class names\n",
        "        \"\"\"\n",
        "        assert len(class_names) == self._num_classes, \\\n",
        "            f\"Expected {self._num_classes} class names, got {len(class_names)}\"\n",
        "        self._class_names = class_names"
      ],
      "metadata": {
        "id": "jrPzD25kRYRn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(\n",
        "    num_classes: int,\n",
        "    input_shape: Tuple[int, int, int] = (3, 416, 416),\n",
        "    class_names: Optional[List[str]] = None\n",
        ") -> BasicYOLO:\n",
        "    \"\"\"Creates and returns a YOLO model.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): Number of classes to predict\n",
        "        input_shape (Tuple[int, int, int]): Input shape as (channels, height, width)\n",
        "        class_names (List[str], optional): Names of the classes. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        BasicYOLO: Initialized YOLO model\n",
        "    \"\"\"\n",
        "    return BasicYOLO(\n",
        "        num_classes=num_classes,\n",
        "        input_shape=input_shape,\n",
        "        class_names=class_names\n",
        "    )"
      ],
      "metadata": {
        "id": "g62it1FeOuWu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example usage"
      ],
      "metadata": {
        "id": "8m6HqfC1X2rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Test parameters\n",
        "    INPUT_SHAPE = (3, 416, 416)\n",
        "    NUM_CLASSES = 3\n",
        "    BATCH_SIZE = 2\n",
        "    CLASS_NAMES = [\"cat\", \"dog\", \"bird\"]\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(\n",
        "        num_classes=NUM_CLASSES,\n",
        "        input_shape=INPUT_SHAPE,\n",
        "        class_names=CLASS_NAMES\n",
        "    )\n",
        "\n",
        "    # Print model info\n",
        "    print(f\"Model Configuration:\")\n",
        "    print(f\"Input shape: {model.get_input_shape()}\")\n",
        "    print(f\"Number of classes: {model.get_num_classes()}\")\n",
        "    print(f\"Class names: {model.get_class_names()}\")\n",
        "\n",
        "    # Test forward pass with sample data\n",
        "    x = torch.randn(BATCH_SIZE, *INPUT_SHAPE)\n",
        "\n",
        "    # Get predictions with class labels\n",
        "    predictions = model.predict(x, threshold=0.3)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nTest Predictions:\")\n",
        "    for i, pred in enumerate(predictions):\n",
        "        print(f\"Image {i + 1} predictions:\")\n",
        "        for class_name, prob in pred.items():\n",
        "            print(f\"  {class_name}: {prob:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeUeYQwiX4lG",
        "outputId": "83300035-0046-490e-aa0b-24505359de7c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Configuration:\n",
            "Input shape: (3, 416, 416)\n",
            "Number of classes: 3\n",
            "Class names: ['cat', 'dog', 'bird']\n",
            "\n",
            "Test Predictions:\n",
            "Image 1 predictions:\n",
            "  cat: 0.359\n",
            "  dog: 0.311\n",
            "  bird: 0.330\n",
            "Image 2 predictions:\n",
            "  cat: 0.359\n",
            "  dog: 0.311\n",
            "  bird: 0.330\n"
          ]
        }
      ]
    }
  ]
}